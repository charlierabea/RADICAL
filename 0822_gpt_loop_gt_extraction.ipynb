{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/charliethebear/Documents/Lab/2023_summer/BERTHop3D/.conda/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Users/charliethebear/Documents/Lab/2023_summer/BERTHop3D/.conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the OpenAI API client\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "backoff.on_exception(backoff.expo, (openai.error.RateLimitError, openai.error.ServiceUnavailableError))\n",
    "def chat_completions_with_backoff(prompt):\n",
    "    parameters = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        # \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "    return openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "system_prompt = \"You are a radiologist. Please help extract multi-label binary classification task labels from the following description as annotation.\\n The response should be a list of labels that are indicated and not ruled out in the description. Other information shouldn't appear in the response. \\n The following list are the labels to identify from the description: [brain atrophy, meningioma, fracture, soft tissue swelling,\thydrocephalus, low density patches,\tenlargement of the ventricular system, enlargement of the sulci, calcified plaques, midline shift, intracranial hepatoma, epidural hepatoma,\tsubdural hepatoma, lacunar infarction,\tcortical infarction, subcortical infarction, herniation, arteriosclerotic encephalopathy. \\n\\n Description: \" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"/Users/charliethebear/Documents/Lab/2023_summer/excel/0814_average_scores.xlsx\")\n",
    "if \"Description\" in data.columns:\n",
    "    description = data[\"Description\"]\n",
    "else:\n",
    "    print(\"The column 'Description' does not exist in the provided DataFrame.\")\n",
    "    description = []\n",
    "\n",
    "for idx, attribute in enumerate(description):\n",
    "    description_prompt = str(description[idx])\n",
    "\n",
    "    example_prompt = \"\\n\\n Example response: brain atrophy, fracture, soft tissue swelling, herniation, arteriosclerotic encephalopathy\"\n",
    "\n",
    "    text_prompt = system_prompt + \"\\n\" + description_prompt + \"\\n\" + example_prompt\n",
    "\n",
    "    response = chat_completions_with_backoff(text_prompt)\n",
    "\n",
    "    answer = response.choices[0][\"message\"][\"content\"]\n",
    "    # add answer to data column[\"predicted_description\"]\n",
    "    data.loc[idx, \"Extracted labels(GPT-3.5)\"] = answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/charliethebear/Documents/Lab/2023_summer/excel/processed_0822_gpt_assisted_feature.xlsx\"\n",
    "data.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
